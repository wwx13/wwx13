(window.webpackJsonp=window.webpackJsonp||[]).push([[45],{384:function(t,s,a){t.exports=a.p+"assets/img/batch_norm.7755a221.png"},593:function(t,s,a){"use strict";a.r(s);var n=a(44),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("hr"),t._v(" "),n("h1",{attrs:{id:"batch-norm"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#batch-norm"}},[t._v("#")]),t._v(" Batch Norm")]),t._v(" "),n("p",[t._v("1.如果和全连接和激活函数配合：一般放在全连接之后，激活之前。")]),t._v(" "),n("ol",{attrs:{start:"2"}},[n("li",[t._v("如果和卷积配合放在卷积之后激活函数之前")])]),t._v(" "),n("p",[t._v("对卷积层来说，批量归⼀化发⽣在卷积计算之后、应⽤激活函数之前。如果卷积计算输出多个通道，我\n们需要对这些通道的输出分别做批量归⼀化，且每个通道都拥有独⽴的拉伸和偏移参数，并均为标量。\n设⼩批量中有m个样本。在单个通道上，假设卷积计算输出的⾼和宽分别为p和q。我们需要对该通道中\nm"),n("em",[t._v("p")]),t._v("q个元素同时做批量归⼀化。对这些元素做标准化计算时，我们使⽤相同的均值和⽅差，即该\n通道中 个元素的均值和⽅差。")]),t._v(" "),n("ol",{attrs:{start:"3"}},[n("li",[t._v("稳定性")])]),t._v(" "),n("p",[t._v("使用批量归一化训练时，我们可以将批量大小设得大一点，从而使批量内样本的均值和方差的计算都较为准确。将训练好的模型用于预测时，我们希望模型对于任意输入都有确定的输出。因此，单个样本的输出不应取决于批量归一化所需要的随机小批量中的均值和方差。一种常用的方法是通过移动平均估算整个训练数据集的样本均值和方差，并在预测时使用它们得到确定的输出。可见，和丢弃层一样，批量归一化层在训练模式和预测模式下的计算结果也是不一样的。")]),t._v(" "),n("div",{staticClass:"custom-block tip"},[n("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),n("p",[t._v("移动平均:")]),t._v(" "),n("p",[t._v("moving_mean = moving_mean * momentum + batch_mean * (1 - momentum)\nmoving_var = moving_var * momentum + batch_var * (1 - momentum)")])]),t._v(" "),n("p",[n("img",{attrs:{src:a(384),alt:"NORM"}})]),t._v(" "),n("h1",{attrs:{id:"layer-norm"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#layer-norm"}},[t._v("#")]),t._v(" Layer Norm")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("LayerNorm")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Module"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Construct a layernorm module (See citation for details)."')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" eps"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# feature same as input last dim. share with batch.")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("super")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("LayerNorm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a_2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Parameter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ones"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b_2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Parameter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("zeros"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("eps "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" eps\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("forward")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# mean(-1) 表示 mean(len(x)), 这里的-1就是最后一个维度，也就是hidden_size维")]),t._v("\n        mean "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" keepdim"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        std "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("std"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" keepdim"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a_2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" mean"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("std "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("eps"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b_2\n\n")])])]),n("p",[t._v("在调用前，应该shape到最后一个维度。参数应该就是最后一个维度的大小。\nlayer norm本身是可以指定对任意张量倒数几维度进行Norm的，但是为了方便其实可以等价为\n先把输入的张量转成需要norm的在倒数第一维度。")]),t._v(" "),n("p",[t._v("layer norm的参数本身和需要归一化元素的数目一样，因为我们是对每个原张量元素进行归一的，也需要每个偏移缩放。\n比如输入batch * 3*5 则权重和偏差参数都为5， 和batch无关。")]),t._v(" "),n("p",[t._v("同理：\nbatch norm的参数应该和非batch维度（即特征维度）的元素数目一样。")])])}),[],!1,null,null,null);s.default=e.exports}}]);