(window.webpackJsonp=window.webpackJsonp||[]).push([[15],{438:function(t,s,a){t.exports=a.p+"assets/img/adversial.bba09b78.png"},439:function(t,s,a){t.exports=a.p+"assets/img/FGM.f3eea30b.png"},440:function(t,s,a){t.exports=a.p+"assets/img/pdg.939f27b3.png"},441:function(t,s,a){t.exports=a.p+"assets/img/regular.eacb68bf.png"},442:function(t,s,a){t.exports=a.p+"assets/img/smart.2f7fe4ac.png"},443:function(t,s,a){t.exports=a.p+"assets/img/smart1.f2e53f82.png"},622:function(t,s,a){"use strict";a.r(s);var n=a(44),r=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"smart"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#smart"}},[t._v("#")]),t._v(" SMART")]),t._v(" "),n("p",[t._v("We describe the proposed learning framework – SMART for robust and efficient fine-tuning of\npre-trained language models. Our framework consists of two important ingredients: SMoothnessinducing Adversarial Regularization and BRegman pRoximal poinT opTimization2")]),t._v(" "),n("h1",{attrs:{id:"背景"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#背景"}},[t._v("#")]),t._v(" 背景")]),t._v(" "),n("h2",{attrs:{id:"对抗思想"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#对抗思想"}},[t._v("#")]),t._v(" 对抗思想")]),t._v(" "),n("p",[t._v("对抗训练是一种引入噪声的训练方式，可以对参数进行正则化，提升模型鲁棒性和泛化能力。")]),t._v(" "),n("p",[t._v("对抗训练的假设是：给输入加上扰动之后，输出分布和原Y的分布一致")]),t._v(" "),n("p",[t._v("有监督的数据下使用交叉熵作为损失：\n"),n("img",{attrs:{src:a(438),alt:"adv"}}),t._v("\n用一句话形容对抗训练的思路，就是在输入上进行梯度上升(增大loss)，在参数上进行梯度下降(减小loss)。由于输入会进行embedding lookup，所以实际的做法是在embedding table上进行梯度上升。")]),t._v(" "),n("p",[t._v("接下来介绍不同的方法，后续方法优化的主要方向有两点：得到更优的扰动 & 提升训练速度")]),t._v(" "),n("p",[n("img",{attrs:{src:a(439),alt:"FGM"}})]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("FGM相比前者就是类似优化算法adagrad和sgd一样的关系。\n伪代码：\n\n对于每个x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("计算x的前向loss、反向传播得到梯度\n  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("根据embedding矩阵的梯度计算出r，并加到当前embedding上，相当于x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("r\n  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("计算x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("r的前向loss，反向传播得到对抗的梯度，累加到"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("的梯度上\n  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("将embedding恢复为"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("时的值\n  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("根据"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("的梯度对参数进行更新\n")])])]),n("h3",{attrs:{id:"pdg"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#pdg"}},[t._v("#")]),t._v(" pdg")]),t._v(" "),n("p",[t._v("设迭代t次确定当前的扰动，则t次前向传播计算梯度，每次移动平均更新当前扰动，并清空这次\n的梯，最后一次使用最后的扰动计算前向损失反向传播正常训练。\n"),n("img",{attrs:{src:a(440),alt:"pdg"}})]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("对于每个x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("计算x的前向loss、反向传播得到梯度并备份\n  对于每步t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("根据embedding矩阵的梯度计算出r，并加到当前embedding上，相当于x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("r"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("超出范围则投影回epsilon内"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.")]),t._v("t不是最后一步"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 将梯度归"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("，根据"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("的x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("r计算前后向并得到梯度\n    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4.")]),t._v("t是最后一步"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" 恢复"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("的梯度，计算最后的x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("r并将梯度累加到"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("上\n  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("将embedding恢复为"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("时的值\n  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("根据"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("的梯度对参数进行更新\n")])])]),n("p",[n("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/98075920",target:"_blank",rel:"noopener noreferrer"}},[t._v("PDG"),n("OutboundLink")],1)]),t._v(" "),n("h2",{attrs:{id:"smoothness-inducing-adversarial-regularization"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#smoothness-inducing-adversarial-regularization"}},[t._v("#")]),t._v(" Smoothness-Inducing Adversarial Regularization")]),t._v(" "),n("p",[t._v("目的： 控制模型微调的复杂度, 增加鲁棒。\n"),n("img",{attrs:{src:a(441),alt:"smo"}}),t._v("\n参考了半监督对抗训练，对抗的目标是最大化扰动前后的输出，在分类任务时loss采用对称的KL散度，回归任务时使用平方损失损失")]),t._v(" "),n("h2",{attrs:{id:"bregman-proximal-point-optimization"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#bregman-proximal-point-optimization"}},[t._v("#")]),t._v(" Bregman Proximal Point Optimization")]),t._v(" "),n("p",[t._v("目的：避免灾难性遗忘\n"),n("img",{attrs:{src:a(442),alt:"smart"}}),t._v(" "),n("img",{attrs:{src:a(443),alt:"smart1"}})]),t._v(" "),n("p",[n("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/396242734",target:"_blank",rel:"noopener noreferrer"}},[t._v("ref"),n("OutboundLink")],1),t._v(" "),n("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/103593948",target:"_blank",rel:"noopener noreferrer"}},[t._v("ref2"),n("OutboundLink")],1)])])}),[],!1,null,null,null);s.default=r.exports}}]);